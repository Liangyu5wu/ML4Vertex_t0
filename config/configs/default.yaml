# Default configuration for transformer model training
model_name: "transformer_default"

# Data parameters
data_dir: "../selected_h5/"
num_files: 50
max_cells: 40
min_cells: 3
cell_selection_feature: "Cell_e"
use_spatial_features: false

# Detector calibration parameters (disabled by default)
use_detector_params: false
emb1_params: [48.5266, 37.56, 28.9393, 23.1505, 18.5468, 13.0141, 8.03724]
emb2_params: [46.2244, 41.5079, 38.5544, 36.9812, 31.2718, 29.7469, 19.331]
emb3_params: [104.325, 106.119, 71.1017, 75.151, 51.2334, 48.2088, 46.6502]
eme1_params: [125.348, 102.888, 86.7558, 59.7355, 55.3299, 41.3032, 23.646]
eme2_params: [272.149, 224.475, 173.443, 135.829, 113.05, 83.8009, 37.1829]
eme3_params: [189.356, 140.293, 111.232, 86.8784, 69.0834, 60.5034, 38.5008]

# Cell filtering parameters
use_cell_track_matching: true
require_valid_cells: true
additional_cell_filters: {}

# Data split parameters
test_size: 0.3
val_split: 0.33333
random_state: 42

# Model architecture parameters
d_model: 128  # Must be divisible by num_heads
num_heads: 8
dff: 256
num_transformer_blocks: 3
dropout_rate: 0.1

# Dense layer parameters
vertex_dense_units: 64
final_dense_units: [256, 128, 64]
final_dropout_rates: [0.3, 0.2, 0.1]
use_batch_norm: true

# Training parameters
batch_size: 64
epochs: 50
learning_rate: 0.0001
lr_reduction_factor: 0.5
early_stopping_patience: 15
lr_patience: 5
min_lr: 0.0000001

# Feature definitions
spatial_features: ["Cell_x", "Cell_y", "Cell_z"]
vertex_spatial_features: ["HSvertex_reco_x", "HSvertex_reco_y", "HSvertex_reco_z"]
all_cell_features:
  - "Cell_x"
  - "Cell_y" 
  - "Cell_z"
  - "Cell_eta"
  - "Cell_phi"
  - "Cell_Barrel"
  - "Cell_layer"
  - "Cell_time_TOF_corrected"
  - "Cell_e"
  - "Cell_significance"
  - "matched_track_pt"
  - "matched_track_deltaR"
skip_normalization: ["Cell_time_TOF_corrected", "Cell_Barrel", "Cell_layer"]
